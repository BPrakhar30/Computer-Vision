{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b78209739e273da3a3bdbb15ea5cc74d",
     "grade": false,
     "grade_id": "cell-c4ab9a740c51dfd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img align=\"center\" src=\"img/course.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7898acafc88387d3f7ce40720bf71ef2",
     "grade": false,
     "grade_id": "cell-3c6401138ee3087d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 16720 (B)  Object Tracking in Videos - Assignment 6 - Q2\n",
    "    Instructor: Kris                          TAs: Arka, Rohan, Rawal, Sheng-Yu, Jinkun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc9f65ed0eacde8b833f81bd82b98d8d",
     "grade": false,
     "grade_id": "cell-951f7cf42448155b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38804a257a8f737c4d975806d09367df",
     "grade": false,
     "grade_id": "cell-8cbbfcc0342ed1ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q2: Matthew-Bakers Inverse Compositional Alignment with Affine Matrix\n",
    "\n",
    "### Q2.1: Implementation (10 PT write-up, 20 PT implementation)\n",
    "Now we will implement the Matthew-Bakers tracker to alleviate the computational costs of the the Lucas-Kanade tracker, as it only calculates the Hessian and Jacobian once per each video. Write the function with the following function signature:\n",
    "\n",
    "```\n",
    "            M = InverseCompositionAffine(It, It1, rect)\n",
    "```\n",
    "that computes the optimal local motion represented by a $2x3$ affine transformation matrix $M$ from frame $I_t$ to frame $I_{t+1}$ that minimizes\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\mathcal{L}=\\sum_{\\mathbf{x}}[\\mathbf{T}(\\mathbf{x})-\\mathbf{I}(\\mathbf{W}(\\mathbf{x} ; \\mathbf{p}))]^{2}. \n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "The inputs are structured identically to Q1.2, but you should replace the forward alignment algorithm with the inverse compositional alignment algorithm. You may also find these materials useful: [link](https://www.ri.cmu.edu/pub_files/pub3/baker_simon_2002_3/baker_simon_2002_3.pdf) and [link](https://www.ri.cmu.edu/pub_files/pub3/baker_simon_2003_3/baker_simon_2003_3.pdf).\n",
    "\n",
    "<span style='color:red'>**Output:**</span> In your write-up: Please include the results of the algorithm on all five videos we have provided along with your code. Compare the results of the Matthew-Bakers Tracker with the previous algorithms you have implemented. How do your algorithms perform on each video? What are the differences of the three algorithms in terms of performance and why do they have those differences? At what point does the algorithm break down and why does this happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.cuda.is_available()\n",
    "print('*' * 50)\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA is found! Tranining on %s.......'%torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    warnings.warn('CUDA not found! Training may be slow......')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0447ca55b183d49aedc2487b700c00a",
     "grade": false,
     "grade_id": "cell-75539a0c38616db4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def InverseCompositionAffine(It, It1, rect, thresh=.025, maxIters=100):\n",
    "    '''\n",
    "    Q2.1: Matthew-Bakers Inverse Compositional Alignment with Affine MAtrix\n",
    "    \n",
    "      Inputs: \n",
    "        It: template image\n",
    "        It1: Current image\n",
    "        rect: Current position of the object\n",
    "        (top left, bottom right coordinates, x1, y1, x2, y2)\n",
    "        thresh: Stop condition when dp is too small\n",
    "        maxIt: Maximum number of iterations to run\n",
    "        \n",
    "      Outputs:\n",
    "        M: Affine mtarix (2x3)\n",
    "    '''\n",
    "    M = np.eye(3)\n",
    "    P = np.zeros((3,3))\n",
    "#     threshold = thresh\n",
    "\n",
    "    x1, y1, x2, y2 = rect\n",
    "\n",
    "    if x2 < x1 or y2 < y1: \n",
    "        return M[: 2]\n",
    "    \n",
    "    s1 = np.arange(It.shape[0])\n",
    "    s2 = np.arange(It.shape[1])\n",
    "    s3 = np.arange(It1.shape[0])\n",
    "    s4 = np.arange(It1.shape[1])\n",
    "        \n",
    "    interit = RectBivariateSpline(s1, s2, It) \n",
    "    interit1 = RectBivariateSpline(s3, s4, It1)\n",
    "    \n",
    "    random_x = np.arange(x1, x2 + 0.1)\n",
    "    random_y = np.arange(y1, y2 + 0.1)\n",
    "    x, y = np.meshgrid(random_x, random_y)\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()     \n",
    "    T_ev = interit.ev(y, x)\n",
    "    \n",
    "    coords_ = np.hstack((x.reshape(-1, 1), y.reshape(-1, 1)))\n",
    "        \n",
    "    T_x = interit.ev(y, x, dx=0, dy=1)\n",
    "    T_y = interit.ev(y, x, dx=1, dy=0)\n",
    "\n",
    "    A = np.zeros((x.shape[0], 2, 6))\n",
    "    \n",
    "    A[:,0,0] = A[:,1,3] =  x\n",
    "    A[:,0,1] = A[:,1,4] =  y\n",
    "    A[:,0,2] = A[:,1,5] =  1\n",
    "    \n",
    "    grad = np.hstack((T_x.reshape(-1, 1), T_y.reshape(-1, 1))).reshape(-1, 1, 2)\n",
    "    \n",
    "    A = np.matmul(grad, A).reshape(-1, 6)\n",
    "    \n",
    "    for i in range(maxIters):\n",
    "\n",
    "        coords = M @ (np.hstack((coords_, np.ones(coords_.shape[0]).reshape(-1, 1))).T)\n",
    "        \n",
    "        x = coords[0].flatten()\n",
    "        y = coords[1].flatten()\n",
    "                \n",
    "        I_ev = interit1.ev(y, x)\n",
    "\n",
    "        b = I_ev - T_ev\n",
    "        \n",
    "        dp = np.linalg.lstsq(A, b, rcond=None)[0] \n",
    "\n",
    "        dp = dp.reshape(2, 3)\n",
    "        \n",
    "        dM = np.eye(3)\n",
    "        dM = dM + np.vstack((dp, np.array([0, 0, 0])))\n",
    "        M = M @ np.linalg.pinv(dM)\n",
    "    \n",
    "        if np.linalg.norm(dp) <= thresh:\n",
    "            break\n",
    "    \n",
    "    return M[: -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test your algorithm and visualize results!\n",
    "\n",
    "# Load data\n",
    "# data_name = 'car2' # could choose from (car1, car2, landing, race, ballet)\n",
    "# data = np.load('./data/%s.npy' % data_name)\n",
    "\n",
    "# obtain the initial rect with format (x1, y1, x2, y2)\n",
    "if data_name == 'car1':\n",
    "    initial = np.array([170, 130, 290, 250])\n",
    "elif data_name == 'car2':\n",
    "    initial = np.array([59, 116, 145, 151])\n",
    "elif data_name == 'landing':\n",
    "    initial = np.array([440, 80, 560, 140])\n",
    "elif data_name == 'race':\n",
    "    initial = np.array([170, 270, 300, 370])\n",
    "elif data_name == 'ballet':\n",
    "    initial = np.array([700, 210, 775, 300])\n",
    "else:\n",
    "    assert False, 'the data name must be one of (car1, car2, landing, race, ballet)'\n",
    "\n",
    "numFrames = data.shape[2]\n",
    "w = initial[2] - initial[0]\n",
    "h = initial[3] - initial[1]\n",
    "\n",
    "# loop over frames\n",
    "rects = []\n",
    "rects.append(initial)\n",
    "\n",
    "for i in range(numFrames-1):\n",
    "\n",
    "    It = data[:,:,i]\n",
    "    It1 = data[:,:,i+1]\n",
    "    rect = rects[i]\n",
    "\n",
    "    # run algorithm and collect rects\n",
    "    M = InverseCompositionAffine(It, It1, rect)\n",
    "    corners = np.array([[rect[0], rect[1], 1], \n",
    "                        [rect[2], rect[3], 1]]).transpose()\n",
    "    newRect = np.matmul(M, corners).transpose().reshape((4, ))\n",
    "    rects.append(newRect)\n",
    "\n",
    "    # Visualize\n",
    "    fig = plt.figure(1)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.add_patch(patches.Rectangle((rect[0], rect[1]), rect[2]-rect[0]+1, rect[3]-rect[1]+1, linewidth=2, edgecolor='red', fill=False))\n",
    "    plt.imshow(It1, cmap='gray')\n",
    "    plt.show()\n",
    "    ax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4e51668c14367108d67297049924981",
     "grade": true,
     "grade_id": "q2_1",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For some transparency: we evaluate on multiple frames in a given video starting from the first frame.\n",
    "# We then compare against the reference implementation and calculate the sum of all differences.\n",
    "# You should not need to tune anything for the autograding. We pass in the same hyperparameters for you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40d90151aa6f37d11f3d3c4c61d5eff9",
     "grade": false,
     "grade_id": "cell-8cbbfcc0342ed1ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q2.2: Comparing Your Algorithms (write-up only, 10 PT)\n",
    "Compare the results of the Matthew-Bakers Tracker with the previous algorithms you have implemented. How do your algorithms perform on each video? What are the differences of the three algorithms in terms of performance and why do we have those differences?  At what point does the algorithm break down and why does this happen?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
