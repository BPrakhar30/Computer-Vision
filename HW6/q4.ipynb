{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"img/course.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16720 (B)  Object Tracking in Videos - Assignment 6 - Q5\n",
    "    Instructor: Kris                          TAs: Arka, Rohan, Rawal, Sheng-Yu, Jinkun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.interpolate import RectBivariateSpline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Multi-Object Tracking by Detection (EC, 45 PT)\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this extra credit problem, you will be introduced to a more modern perspective on tracking. In the previous problems, you implemented single-object tracking with a classical method, the LK tracker. Multi-object tracking (MOT), on the other hand, is a richer and more useful problem to attack. One approach to this problem is called tracking by detection. In this paradigm, for each frame of a video, we produce object detections (typically from a learned object detection neural net). These are called proposals, and are often bounding boxes. In the next step, we associate those boxes with any existing tracked objects. For a more in-depth overview, please see the following [link](https://arshren.medium.com/an-introduction-to-object-tracking-9fd6249a76b6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.1 Loading the bounding boxes, video and visualization (5 pts)\n",
    "\n",
    "In the spirit of the World Cup, we will be evaluating your method on a short excerpt from a [famous soccer clip](https://youtu.be/uBa8dYlqv8Y). We'll begin by loading and visualizing the input. We have already computed bounding boxes for you, which are available in ```soccer_boxes.json```. The images to use in the video are available in ```soccer_images.npy``` Both files can be download at this [link](https://www.dropbox.com/sh/uovrr3cgtehhtuc/AAATS-GtGEwfS-z2MXRNku7Ea?dl=0).\n",
    "\n",
    "Fill in the functions below. For testing, your result for the visualization on the 124th frame should look something like\n",
    "\n",
    "<img align=\"center\" src=\"img/sample_bbox_img.jpg\" width=\"800\">\n",
    "\n",
    "Please submit an image of the bounding boxes rendered on the 1st frame of the sequence along with your code for this question to the writeup PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_boxes(img_path, box_path):\n",
    "\n",
    "    data = 'soccer_images'\n",
    "    imgs = np.load(img_path % data,allow_pickle = True)\n",
    "\n",
    "    data_box = 'soccer_boxes'\n",
    "    f = open(box_path % data_box)\n",
    "    boxes = json.load(f)\n",
    "    \n",
    "    return imgs, boxes\n",
    "c = ['red','blue','grey','green','orange','black','white','brown','cyan','violet','yellow','purple']\n",
    "def render_single_frame(image, bboxes, colors = False):\n",
    "\n",
    "    if colors == 1:\n",
    "        fig = plt.figure(1)\n",
    "        ax = fig.add_subplot(111)\n",
    "        for i in bboxes:\n",
    "            ax.add_patch(patches.Rectangle((i[0],i[1]),i[2]-i[0]+1,i[3]-i[1]+1, \n",
    "                                           linewidth = 2, edgecolor = 'green', fill = False))\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        ax.clear()\n",
    "    else:\n",
    "        fig = plt.figure(1)\n",
    "        ax = fig.add_subplot(111)\n",
    "        o = 0\n",
    "        for i in bboxes:\n",
    "            ax.add_patch(patches.Rectangle((i[0],i[1]),i[2]-i[0]+1,i[3]-i[1]+1,\n",
    "                                           linewidth=2, edgecolor=colors[o], fill=False))\n",
    "            \n",
    "            o = o + 1\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        ax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = load_images_and_boxes('./%s.npy','./%s.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_single_frame(a[124],b[124]['boxes'], colors = True)\n",
    "render_single_frame(a[0],b[0]['boxes'], colors = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.2 Implementing a similarity metric (10 pts)\n",
    "\n",
    "In order to do track association, we need a way to measure how similar two bounding boxes are to each other. One way to do this is intersection-over-union (IoU). An overview of how to compute IoU is provided [here](https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/). Below, you will implement a function to compute IoU. The input will be a set of N bounding boxes (representing the boxes in the reference frame), and a set of M bounding boxes (representing the boxes in the next frame) and the output will be an NxM matrix, with the ```[i, j]```th entry correspoding to bounding box ```i``` in the reference frame's IoU with bounding box ```j``` of the next frame.\n",
    "\n",
    "For this question, please submit the matrix of IoUs between the boxes on the 124th and 125th frames, as well as your code to the writeup PDF, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlappingArea(l_1, r_1, l_2, r_2):\n",
    "    xx = 0\n",
    "    yy = 1\n",
    "\n",
    "    area_ = abs(l_1[xx] - r_1[xx]) * abs(l_1[yy] - r_1[yy])\n",
    "\n",
    "    area__ = abs(l_2[xx] - r_2[xx]) * abs(l_2[yy] - r_2[yy])\n",
    "\n",
    "    x_dist = (min(r_1[xx], r_2[xx]) - max(l_1[xx], l_2[xx]))\n",
    " \n",
    "    y_dist = (min(r_1[yy], r_2[yy]) - max(l_1[yy], l_2[yy]))\n",
    "    \n",
    "    area_ = 0\n",
    "    \n",
    "    if x_dist > 0 and y_dist > 0:\n",
    "        area_ = x_dist * y_dist\n",
    "    \n",
    "    ar = (area_ + area__ - area_)\n",
    "    return ar, area_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2):\n",
    "\n",
    "    len_box1 = len(boxes1)\n",
    "    len_box2 = len(boxes2)\n",
    "    \n",
    "    m = np.zeros((len_box1,len_box2))\n",
    "    for i in range(len_box1):\n",
    "        for j in range(len_box2):\n",
    "            \n",
    "            a,b = overlappingArea(np.array((boxes1[i][0],boxes1[i][1])),\n",
    "                                  np.array((boxes1[i][2],boxes1[i][3])),np.array((boxes2[j][0],boxes2[j][1])),\n",
    "                                  np.array((boxes2[j][2],boxes2[j][3])))\n",
    "            m[i][j] = b/a\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = compute_iou(b[124]['boxes'],b[125]['boxes'])\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_single_frame(a[124],b[124]['boxes'], colors=1)\n",
    "render_single_frame(a[125],b[125]['boxes'], colors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(250):\n",
    "    render_single_frame(a[i],b[i]['boxes'], colors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b[1]['boxes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.3 Matching with the Hungarian Algorithm (10 pts)\n",
    "\n",
    "Given a matrix of similarities, the next step in tracking by detection is to find the bounding box that corresponds most to the previous frame. In essence, the idea is to find the bounding box that has the closest IoU to a bounding box in a previous frame. The challenging part is to remove this bounding box from contention for other matches. This problem is known as the optimal cost assignment problem. The Hungarian algorithm is the most commonly used method to solve this problem, and is implemented in ```scipy.optimize.linear_sum_assignment```. Below, you will implement a function ```compute_assignment``` that will produce such a matching. \n",
    "\n",
    "Some notes to keep in mind: ```scipy```'s implementation uses costs, so you will need to use the negative of the similarities you computed in the previous part. Additionally, since the IoU of a bounding box with itself is 1, you will need to set the diagonal entries of the cost matrix to some high value so they are not picked. Finally, it's likely there will be matches with very low IoU scores. Please use the ```threshold``` parameter to filter out any matches that are below ```threshold``` IoU.\n",
    "\n",
    "Please submit your code for this section to the writeup PDF, along with the output run on the IOU matrix computed between the 124th and 125th images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_assignment(iou, threshold=0.8):\n",
    "\n",
    "    thresh = threshold\n",
    "    shape0 = iou.shape[0]\n",
    "    shape1 = iou.shape[1]\n",
    "    b1 = np.zeros(shape0)\n",
    "    b2 = np.zeros(shape1)\n",
    "    \n",
    "    for i in range(shape0):\n",
    "        for j in range(shape1):\n",
    "            if iou[i][j] > thresh:\n",
    "                b1[i] = 1\n",
    "                b2[j] = 1\n",
    "    \n",
    "    return np.array(b1), np.array(b2)\n",
    "\n",
    "iou = compute_iou(b[124][\"boxes\"], b[125][\"boxes\"])\n",
    "print(\"iou matrix\", iou)\n",
    "b1__iou,b2__iou = compute_assignment(iou, threshold = 0.8)\n",
    "print(\"b1_iou\" , b1__iou)\n",
    "print(\"b2_iou\" , b2__iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.4 Putting it all together (20 pts)\n",
    "\n",
    "Now, you will put all the pieces together that you implemented above to create a full tracking system. You will maintain a set of tracks throughout the video. At the beginning, no tracks will exist, only detections. In each successive frame, you will read in the detections for that frame and associate the new detections to the previous ones, and create candidate tracks. If a candidate track has persisted for P frames, you will add it to the list of tracks. If a track has not had a match in K frames, you will remove it from the list of tracks. For each frame, you will render the bounding boxes corresponding to every track. Once a track is removed from the list, do not render its bounding box. \n",
    "\n",
    "The hyperparameters you will use for the tracker are:\n",
    "\n",
    "P: number of frames a candidate track must exist before it is added to the list of tracks\n",
    "K: number of frames a track must have no match for before it is removed from the list of tracks\n",
    "iou_thresh: threshold to be used for whether a match is strong enough to be added to a track.\n",
    "\n",
    "\n",
    "For your submission for this part, please submit 10 images (with bounding boxes) from successive frames at any point in the video. Bounding boxes belonging to the same track should be the same color. Please also submit your code to the writeup PDF. \n",
    "\n",
    "Please note that the output will NOT be perfect! There should be ID switches and the tracker, even if implemented correctly, will likely fail in several frames. This should hopefully demonstrate to you that tracking is a tough problem and show why it is a hot research area today :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_tracker(images, boxes,rang, P, K, iou_thresh):\n",
    "\n",
    "    all_frame0 = []\n",
    "    all_frame1 = []\n",
    "    all_frame2 = []\n",
    "    a = images\n",
    "    b = boxes\n",
    "    \n",
    "    for i in range(249):\n",
    "        all_frame0.append(compute_iou(b[i]['boxes'], b[i+1]['boxes']))\n",
    "    \n",
    "    for i in range(249):\n",
    "        b1, b2 = compute_assignment(all_frame0[i], iou_thresh)\n",
    "        all_frame1.append(b1)\n",
    "        all_frame2.append(b2)\n",
    "        \n",
    "    c = []\n",
    "    for i in range(250-P):\n",
    "        a_frame = all_frame1[i]\n",
    "        u = a_frame.shape[0]\n",
    "        array_u = np.zeros(u)\n",
    "        \n",
    "        for j in range(P):\n",
    "            if all_frame1[i+j].shape[0] >= u:\n",
    "                for k in range(u):\n",
    "                    if a_frame[k] == 1 and all_frame1[i+j][k] == 1:\n",
    "                        array_u[k] = array_u[k] + 1\n",
    "            else:\n",
    "                for o in range(all_frame1[i + j].shape[0]):\n",
    "                    if a_frame[o] == 1 and all_frame1[i+j][o] == 1:\n",
    "                        array_u[o] = array_u[o]+1\n",
    "        c.append(array_u)\n",
    "    import copy\n",
    "    \n",
    "    for i in range(len(c)):\n",
    "        for j in range(c[i].shape[0]):\n",
    "            if c[i][j] < P-K-1:\n",
    "                c[i][j] = 0\n",
    "    b_a = []\n",
    "    b_d = []\n",
    "    for i in range(len(c)):\n",
    "        b_d = []\n",
    "        for j in range(c[i].shape[0]):\n",
    "            if c[i][j]>0:\n",
    "                b_d.append(b[i]['boxes'][j])\n",
    "        b_a.append(b_d)\n",
    "    for i in range(len(c)):\n",
    "        print(\"No of bounding boxes - \",len(b_a[i]))\n",
    "        render_single_frame(a[i],b_a[i],rang)\n",
    "\n",
    "p = run_tracker(a, b, c, 10, 3, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
