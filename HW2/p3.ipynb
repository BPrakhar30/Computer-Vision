{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99add00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97a68f63",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b622cbe231219cd333a0c5198d4f767",
     "grade": false,
     "grade_id": "cell-be3fe8a24d877d09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img align=\"center\" src=\"figures/course.png\" width=\"800\">\n",
    "\n",
    "#                                    16720 (B) Bag of Visual Words - Assignment 2\n",
    "\n",
    "     Instructor: Kris Kitani                   TAs: Sheng-Yu, Jinkun, Rawal, Arka, Rohan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e00ddf3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "676716f51a0534ffa360da4ccdb48472",
     "grade": false,
     "grade_id": "cell-e15ca317eaa41fb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipynb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mp1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_visual_words\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipynb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mp2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_image_feature, distance_to_set\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ipynb'"
     ]
    }
   ],
   "source": [
    "import nbimporter\n",
    "import numpy as np\n",
    "import skimage\n",
    "import multiprocess\n",
    "import threading\n",
    "import queue\n",
    "import os,time\n",
    "import math\n",
    "from ipynb.fs.defs.p1 import get_visual_words\n",
    "from ipynb.fs.defs.p2 import get_image_feature, distance_to_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93858e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from function2 import get_visual_words\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "729ebbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from function2 import get_image_feature, distance_to_set, get_visual_words, extract_filter_responses, get_feature_from_wordmap, get_feature_from_wordmap_SPM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f68ec46",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6b4bd161f74c53045778dc7514a8ee4",
     "grade": false,
     "grade_id": "cell-5de8321c73982d7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## For Autograding P3, ensure uploading `conf_matrix.npy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c20957e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f4d1f07da6458c74287795f94f96536",
     "grade": false,
     "grade_id": "cell-2147ec14a9f2bf1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Quantitative Evaluation\n",
    "\n",
    "#### Calculating confusion matrix\n",
    "Qualitative evaluation is all well and good (and very important for diagnosing performance gains and losses), but we want some hard numbers.\n",
    "\n",
    "Load the corresponding test images and their labels, and compute the predicted labels of each, i.e., compute its distance to every image in training set and return the label with least distance difference as the predicted label. To quantify the accuracy, you will compute a confusion matrix $C$: given a classification problem, the entry $C(i,j)$ of a confusion matrix counts the number of instances of class $i$ that were predicted as class $j$. When things are going well, the elements on the diagonal of $C$ are large, and the off-diagonal elements are small. Since there are 8 classes, $C$ will be $8 \\times 8$. The accuracy, or percent of correctly classified images, is given by the trace of $C$ divided by the sum of $C$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb82ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e1da8d3b8b10f7d4168ec44b31082346",
     "grade": false,
     "grade_id": "cell-5400ddbf4b5a9cde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3.1.1 (10 Points -> 5 Autograder + 5 WriteUp)\n",
    "Implement the function\n",
    "```\n",
    "            def evaluate_recognition_system():\n",
    "```\n",
    "that tests the system and outputs the confusion matrix.\n",
    "\n",
    "Report the confusion matrix and accuracy for your results in your write-up. This does not have to be formatted prettily: if you are using LaTeX, you can simply copy/paste it into a $verbatim$ environment. Additionally, do not worry if your accuracy is low: with 8 classes, chance is $12.5\\%$. To give you a more sensible number, a reference implementation _with_ spatial pyramid matching gives an overall accuracy of around $50\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "826e61ed",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "265c7da210d2cc64502b1a013289f0de",
     "grade": false,
     "grade_id": "cell-7f6a78a4e33d1ca4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained features shape:  (1000, 4200)\n",
      "Test data shape:  (160,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels shape:  (160,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "accuracy = 0.6\n",
      "conf_mat = array([[14.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., 14.,  0.,  0.,  0.,  1.,  2.,  1.],\n",
      "       [ 0.,  0., 15.,  3.,  4.,  1.,  0.,  2.],\n",
      "       [ 1.,  3.,  2., 10.,  0.,  3.,  1.,  6.],\n",
      "       [ 2.,  0.,  0.,  0., 10.,  1.,  0.,  0.],\n",
      "       [ 1.,  1.,  0.,  1.,  7., 12.,  2.,  0.],\n",
      "       [ 0.,  3.,  1.,  1.,  3.,  2., 11.,  0.],\n",
      "       [ 0.,  1.,  1.,  4.,  2.,  0.,  1., 10.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def helper_func(args):\n",
    "    file_path, dictionary, layer_num, K, trained_features, train_labels = args\n",
    "    # YOUR CODE HERE\n",
    "    _, feature = get_image_feature(file_path, dictionary, layer_num, K)\n",
    "    distances = distance_to_set(feature, trained_features)\n",
    "    nearest_image_idx = np.argmax(distances)\n",
    "    pred_label = train_labels[nearest_image_idx]    \n",
    "    \n",
    "    return [file_path, pred_label, nearest_image_idx]\n",
    "\n",
    "\n",
    "def evaluate_recognition_system(num_workers=2):\n",
    "    '''\n",
    "    Evaluates the recognition system for all test images and returns the confusion matrix.\n",
    "\n",
    "    [input]\n",
    "    * num_workers: number of workers to process in parallel\n",
    "\n",
    "    [output]\n",
    "    * conf: numpy.ndarray of shape (8,8)\n",
    "    * accuracy: accuracy of the evaluated system\n",
    "    '''\n",
    "    '''\n",
    "    HINTS\n",
    "    (1) You may wish to use multiprocessing to improve speed (NO Extra Points)\n",
    "    (2) You may create helper function (in the same cell) to enable multiprocessing\n",
    "    (3) Think Nearest Neighbor -> assign label using element closest in train set\n",
    "    '''\n",
    "    from function2 import helper_func\n",
    "    test_data = np.load(\"./data/test_data.npz\")\n",
    "    trained_system = np.load(\"trained_system.npz\")\n",
    "    \n",
    "    image_names = test_data['files']\n",
    "    test_labels = test_data['labels']\n",
    "\n",
    "    trained_features = trained_system['features']\n",
    "    train_labels = trained_system['labels']\n",
    "    \n",
    "    dictionary = trained_system['dictionary']\n",
    "    SPM_layer_num = trained_system['SPM_layer_num']\n",
    "    SPM_layer_num = int(SPM_layer_num)\n",
    "    K = dictionary.shape[0]\n",
    "\n",
    "    print(\"Trained features shape: \", trained_features.shape)\n",
    "    print(\"Test data shape: \", image_names.shape)\n",
    "\n",
    "    \n",
    "    # ----- TODO -----\n",
    "    '''\n",
    "    HINTS:\n",
    "    1.> Think almost exactly similar to Q1.2.2\n",
    "    2.> Create a list of arguments and use multiprocessing library\n",
    "    3.> We can define a helper function which can take in the arguments (file_path, dictionary, SPM_layer_num,\n",
    "        trained_features,...) as input and return (file_path, label, nearest neighbor index)\n",
    "    4.> We can use python dictionary and file_path to have the output in correct order\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "   \n",
    "    list_of_args = []\n",
    "    for i in tqdm(range(len(image_names))):\n",
    "        full_image_name = './data/' + image_names[i]\n",
    "        list_of_args.append([full_image_name, dictionary, SPM_layer_num, K, trained_features, train_labels])\n",
    "    \n",
    "    import skimage, multiprocessing\n",
    "    with multiprocessing.Pool(num_workers) as p:\n",
    "        out = p.map(helper_func, list_of_args)\n",
    "            \n",
    "    '''\n",
    "    HINTS:\n",
    "    1.> Can use the file_name (path) to place the labels back in original order of input to multiprocessing\n",
    "    '''    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    ordered_labels, indices = [label for path, label, _ in out], [index for _, _, index in out]\n",
    "    ordered_labels = np.array(ordered_labels, dtype=int)\n",
    "    print(\"Predicted labels shape: \", ordered_labels.shape)\n",
    "    \n",
    "    '''\n",
    "    HINT:\n",
    "    1.> Compute the confusion matrix (8x8)\n",
    "    2.> Remember to save and upload the confusion matrix\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    conf_matrix = np.zeros((8, 8))\n",
    "    for i in tqdm(range(ordered_labels.shape[0])):        \n",
    "        conf_matrix[test_labels[i], ordered_labels[i]] += 1\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)    \n",
    "    np.save(\"./conf_matrix.npy\",conf_matrix)\n",
    "    return conf_matrix, accuracy\n",
    "\n",
    "## NOTE: comment out the lines below before submitting to gradescope\n",
    "    #conf_matrix, accuracy = evaluate_recognition_system()\n",
    "## We expect the accuracy to be greater than 0.45\n",
    "\n",
    "conf_mat, accuracy = evaluate_recognition_system()\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f'{accuracy = }')\n",
    "print(f'{conf_mat = }')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c86fb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "427973e4258d05e7dab0993c06bb805d",
     "grade": false,
     "grade_id": "cell-29cb1f1fda7fe0e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<font color=\"blue\">**Submit the Confusion Matrix and the Accuracy Value in the WriteUp**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23665b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8bbe72feb9acd4b2f967821a1898c893",
     "grade": false,
     "grade_id": "cell-17f9ee303096151f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3.1.2 (5 points WriteUp):\n",
    "<font color=\"blue\"> As there are some classes/samples that are more difficult to classify than the rest using the bags-of-words approach, they are more easily classified incorrectly into other categories. **List some of these classes/samples and discuss why they are more difficult in your write-up.** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efe3fc5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62ee0acb8bbc19685e9d1ea0fe5549d3",
     "grade": false,
     "grade_id": "cell-62c3ca3a5bf0dda0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q3.1.3 [Extra Credit](10 points) Manually Graded:\n",
    "\n",
    "Now that you have seen how well your recognition system can perform on a set of real images, you can experiment with different ways of improving this baseline system. Here are a few suggestions:\n",
    "\n",
    "* Hyperparameter Tuning: here is a list of hypterparameters in the system that you can tune to get better performance for your system:\n",
    "        \n",
    "        * `filter_scales`: a list of filter scales used in extracting filter response;\n",
    "        * `K`: the number of visual words and also the size of the dictionary;\n",
    "        * `alpha`: the number of sampled pixels in each image when creating the dictionary;\n",
    "        * `L`: the number of spatial pyramid layers used in feature extraction.\n",
    "        \n",
    "* Image manipulation: Try using image augmentation techniques such as (1) random-crop, (2) flipping, (3) add noise, (4) jittering, etc. to obtain more training data for your system. You can also try resizing the images, subtracting the mean color, etc. \n",
    "\n",
    "* Better classifier: in part 2 we used the nearest neighbor classifier to classify test images. However, with our extracted SPM features from training images, we can use other classifiers such as multi-class logistic regression, multi-class support vector machine, etc. to gain better performance. For this, you can use implementation of these algorithms from `scipy`.\n",
    "\n",
    "\n",
    "Tune the system you build to reach around 65\\% accuracy on the provided test set (``data/test_data.npz``). <font color=\"blue\">**In your writeup, document what you did to achieve such performance: (1) what you did, (2) what you expected would happen, and (3) what actually happened.** Also, include a file called ``custom.py/ipynb`` for running your code. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90920270",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d2a1b2dad9e93ba64e13ed1ad03be2c",
     "grade": false,
     "grade_id": "cell-a0d3c7383fe4f8cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q3.1.4 [Extra Credit] (25 points): Manually Graded\n",
    "**GIST feature descriptor:** As introduced during the lecture, GIST feature descriptor is a feature extractor based on Gabor Filters. When we apply it to images, we have to implement the 2D Gabor Filters as described below\n",
    "\n",
    "<img align=\"center\" src=\"figures/gist.png\" width=\"800\">\n",
    "\n",
    "In this part, please try to derive GIST features of images and study its effect to the performance of our built recognition system. The extra credits come from two parts:\n",
    "\n",
    "* (10 points) Implement GIST feature extractor and visualize the features from the provided image `sun_aydaknxraiwghvmi.jpg`.\n",
    "* (10 points) Try to incorporate the GIST features into the recognition system. You can feel free to tune the parameters and choose your classifier. Explain your observations and reasoning.\n",
    "\n",
    "<font color=\"blue\">**In your writeup (5 points): How does GIST descriptor affect the performance? Better or worse? Explain your reasoning?**\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2333b1bb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "047b0b0258b66ddbf5130082bcce691d",
     "grade": true,
     "grade_id": "cell-3debc253c7bf7c0c",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_GIST():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def evaluate_recognition_System_GIST():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1185d921",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c362e00628e6d24678258560cff5ea75",
     "grade": true,
     "grade_id": "q_3_1_1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec934e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
